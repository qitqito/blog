{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeZeroのMNISTに畳み込み層とプーリング層とDropoutを追加して実験\n",
    "「[ゼロから作るDeep Learning ❸](https://www.oreilly.co.jp/books/9784873119069/)ステップ51 MNISTの学習」の[`deep-learning-from-scratch-3/examples/mnist.py`](https://github.com/oreilly-japan/deep-learning-from-scratch-3/blob/master/examples/mnist.py)は、次のようなネットワーク構成になっています。\n",
    "\n",
    " - `(1, 28, 28)入力→(784,)配列→Linear(1000)→ReLU→Linear(1000)→ReLU→Linear(10)出力`\n",
    " - 最適化手法：Adam\n",
    "\n",
    "学習経過は次のようになります。\n",
    "\n",
    "```bash\n",
    "$ python -m examples.mnist\n",
    "epoch: 1\n",
    "train loss: 0.19297177767846732, accuracy: 0.9425166666666667\n",
    "test loss: 0.0870012722350657, accuracy: 0.972\n",
    "epoch: 2\n",
    "train loss: 0.07911744002679673, accuracy: 0.9756333333333334\n",
    "test loss: 0.08153347594663501, accuracy: 0.9735\n",
    "epoch: 3\n",
    "train loss: 0.05772087200079113, accuracy: 0.9810833333333333\n",
    "test loss: 0.06439740799571154, accuracy: 0.9804\n",
    "epoch: 4\n",
    "train loss: 0.04381801278757242, accuracy: 0.9858\n",
    "test loss: 0.07971655959896452, accuracy: 0.9763\n",
    "epoch: 5\n",
    "train loss: 0.03815114084631205, accuracy: 0.9882666666666666\n",
    "test loss: 0.07151200462241832, accuracy: 0.9778\n",
    "```\n",
    "\n",
    "これに次のような、標準的な畳み込み層、プーリング層、ドロップアウトを追加したモデルを作成します。\n",
    "\n",
    " - `(1, 28, 28)入力→Conv→ReLU→Pool(2)→Linear(1000)→ReLU→Dropout→Linear(1000)→ReLU→Dropout→Linear(10)出力`\n",
    "   - `Conv`は、カーネルサイズ=3、ストライドサイズ=1、パディングサイズ=1\n",
    "   - 入力データサイズ28 + 2 * パディングサイズ1 - カーネルサイズ3 // ストライドサイズ1 + 1 = 出力サイズ28\n",
    "   - 2x2プーリングなので全結合層`Linear(1000)`に入る時点で縦横半分の14x14となる。\n",
    "\n",
    "実行は、`pip install dezero`（Jupyterなら`!pip install dezero`）でDeZeroをインストールして次を実行するか、\n",
    "[`qitqito/dezero_study/mnist_plus.py`](https://github.com/qitqito/dezero_study/blob/master/mnist_plus.py)をダウンロードして`python -m mnist_plus`などして下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "train loss: 3.2967599945267043, accuracy: 0.7726333333333333\n",
      "test loss: 0.6105298531055451, accuracy: 0.841\n",
      "epoch: 2\n",
      "train loss: 0.4918030514443914, accuracy: 0.8647833333333333\n",
      "test loss: 0.39708854403346777, accuracy: 0.8898\n",
      "epoch: 3\n",
      "train loss: 0.365787100456655, accuracy: 0.8968166666666667\n",
      "test loss: 0.3391792545514181, accuracy: 0.9072\n",
      "epoch: 4\n",
      "train loss: 0.31472394374509655, accuracy: 0.9104833333333333\n",
      "test loss: 0.33774808773770926, accuracy: 0.9031\n",
      "epoch: 5\n",
      "train loss: 0.2928329927722613, accuracy: 0.9176166666666666\n",
      "test loss: 0.30439508248120545, accuracy: 0.9157\n",
      "epoch: 6\n",
      "train loss: 0.2737082013487816, accuracy: 0.9220666666666667\n",
      "test loss: 0.2845079012773931, accuracy: 0.9228\n",
      "epoch: 7\n",
      "train loss: 0.24680014058947564, accuracy: 0.92935\n",
      "test loss: 0.28378744328394534, accuracy: 0.9223\n",
      "epoch: 8\n",
      "train loss: 0.23471303268025318, accuracy: 0.9321666666666667\n",
      "test loss: 0.27566407042555513, accuracy: 0.9266\n",
      "epoch: 9\n",
      "train loss: 0.21447662274663648, accuracy: 0.9387333333333333\n",
      "test loss: 0.2557909615244716, accuracy: 0.9328\n",
      "epoch: 10\n",
      "train loss: 0.17519887572464843, accuracy: 0.9480833333333333\n",
      "test loss: 0.20000756379682572, accuracy: 0.9445\n",
      "epoch: 11\n",
      "train loss: 0.1535407663229853, accuracy: 0.9543666666666667\n",
      "test loss: 0.17418874572496862, accuracy: 0.95\n",
      "epoch: 12\n",
      "train loss: 0.128863106208543, accuracy: 0.96085\n",
      "test loss: 0.14710670401575043, accuracy: 0.9567\n",
      "epoch: 13\n",
      "train loss: 0.1193117741898944, accuracy: 0.9644833333333334\n",
      "test loss: 0.13540442480705678, accuracy: 0.9611\n",
      "epoch: 14\n",
      "train loss: 0.11357438637875021, accuracy: 0.9650166666666666\n",
      "test loss: 0.14487418973236343, accuracy: 0.9601\n",
      "epoch: 15\n",
      "train loss: 0.10861809722458322, accuracy: 0.9663333333333334\n",
      "test loss: 0.14201724069891497, accuracy: 0.9611\n",
      "epoch: 16\n",
      "train loss: 0.10236691535140077, accuracy: 0.9684166666666667\n",
      "test loss: 0.14015006882196757, accuracy: 0.9598\n",
      "epoch: 17\n",
      "train loss: 0.10014666023974618, accuracy: 0.9696833333333333\n",
      "test loss: 0.14514980674837716, accuracy: 0.9618\n",
      "epoch: 18\n",
      "train loss: 0.09907583203942825, accuracy: 0.9695666666666667\n",
      "test loss: 0.1305210689175874, accuracy: 0.9628\n",
      "epoch: 19\n",
      "train loss: 0.10227264529559761, accuracy: 0.9690833333333333\n",
      "test loss: 0.14776304945116864, accuracy: 0.9622\n",
      "epoch: 20\n",
      "train loss: 0.09374648537564402, accuracy: 0.9714166666666667\n",
      "test loss: 0.13284143024939113, accuracy: 0.9644\n"
     ]
    }
   ],
   "source": [
    "import dezero\n",
    "import dezero.functions as F\n",
    "from dezero import DataLoader\n",
    "from dezero.models import Model\n",
    "import dezero.layers as L\n",
    "\n",
    "\n",
    "class MNISTPlus(Model):\n",
    "    def __init__(self, hidden_size=100):\n",
    "        super().__init__()\n",
    "        self.conv1 = L.Conv2d(1, kernel_size=3, stride=1, pad=1)\n",
    "        #self.conv2 = L.Conv2d(1, kernel_size=3, stride=1, pad=1)\n",
    "        self.fc3 = L.Linear(hidden_size)\n",
    "        self.fc4 = L.Linear(hidden_size)\n",
    "        self.fc5 = L.Linear(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) # 28x28\n",
    "        x = F.pooling(x, 2, 2) # 14x14\n",
    "        #x = F.relu(self.conv2(x))\n",
    "        #x = F.pooling(x, 2, 2)\n",
    "        x = F.reshape(x, (x.shape[0], -1)) # 14x14を196に\n",
    "        x = F.dropout(F.relu(self.fc3(x)))\n",
    "        x = F.dropout(F.relu(self.fc4(x)))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "max_epoch = 20\n",
    "batch_size = 100\n",
    "\n",
    "train_set = dezero.datasets.MNIST(train=True, transform=None) # 28x28のまま\n",
    "test_set = dezero.datasets.MNIST(train=False, transform=None) # 28x28のまま\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size, shuffle=False)\n",
    "\n",
    "model = MNISTPlus(1000)\n",
    "optimizer = dezero.optimizers.Adam().setup(model)\n",
    "optimizer.add_hook(dezero.optimizers.WeightDecay(1e-4))  # Weight decay\n",
    "\n",
    "if dezero.cuda.gpu_enable:\n",
    "    train_loader.to_gpu()\n",
    "    test_loader.to_gpu()\n",
    "    model.to_gpu()\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        acc = F.accuracy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "        sum_acc += float(acc.data) * len(t)\n",
    "\n",
    "    print('epoch: {}'.format(epoch+1))\n",
    "    print('train loss: {}, accuracy: {}'.format(\n",
    "        sum_loss / len(train_set), sum_acc / len(train_set)))\n",
    "\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    with dezero.no_grad():\n",
    "        for x, t in test_loader:\n",
    "            y = model(x)\n",
    "            loss = F.softmax_cross_entropy(y, t)\n",
    "            acc = F.accuracy(y, t)\n",
    "            sum_loss += float(loss.data) * len(t)\n",
    "            sum_acc += float(acc.data) * len(t)\n",
    "\n",
    "    print('test loss: {}, accuracy: {}'.format(\n",
    "        sum_loss / len(test_set), sum_acc / len(test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 考察\n",
    "全結合層に畳み込み層・プーリング層・Dropoutを追加したら学習性能が悪化しました。\n",
    "\n",
    "MNISTの画像が小さ過ぎて畳み込みやプーリングが情報を減らしてしまうのかも知れません。Dropoutも有無で実験したところ学習を遅くしてるように思われます。全結合層は1000より小さくしても良いかも知れません。。。\n",
    "\n",
    "自分には、知識不足でろくな考察ができないと分かったので、当分は深層学習などを色々学んでいき、ブログ一記事分たまったらその都度書いていこうと思います。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
